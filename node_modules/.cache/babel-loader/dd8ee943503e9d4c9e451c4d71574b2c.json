{"ast":null,"code":"/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ContainerState} ContainerState\n * @typedef {import('micromark-util-types').Exiter} Exiter\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\nimport { factorySpace } from 'micromark-factory-space';\nimport { asciiDigit, markdownSpace } from 'micromark-util-character';\nimport { codes } from 'micromark-util-symbol/codes.js';\nimport { constants } from 'micromark-util-symbol/constants.js';\nimport { types } from 'micromark-util-symbol/types.js';\nimport { ok as assert } from 'uvu/assert';\nimport { blankLine } from './blank-line.js';\nimport { thematicBreak } from './thematic-break.js';\n/** @type {Construct} */\n\nexport const list = {\n  name: 'list',\n  tokenize: tokenizeListStart,\n  continuation: {\n    tokenize: tokenizeListContinuation\n  },\n  exit: tokenizeListEnd\n};\n/** @type {Construct} */\n\nconst listItemPrefixWhitespaceConstruct = {\n  tokenize: tokenizeListItemPrefixWhitespace,\n  partial: true\n};\n/** @type {Construct} */\n\nconst indentConstruct = {\n  tokenize: tokenizeIndent,\n  partial: true\n}; // To do: `markdown-rs` parses list items on their own and later stitches them\n// together.\n\n/**\n * @type {Tokenizer}\n * @this {TokenizeContext}\n */\n\nfunction tokenizeListStart(effects, ok, nok) {\n  const self = this;\n  const tail = self.events[self.events.length - 1];\n  let initialSize = tail && tail[1].type === types.linePrefix ? tail[2].sliceSerialize(tail[1], true).length : 0;\n  let size = 0;\n  return start;\n  /** @type {State} */\n\n  function start(code) {\n    assert(self.containerState, 'expected state');\n    const kind = self.containerState.type || (code === codes.asterisk || code === codes.plusSign || code === codes.dash ? types.listUnordered : types.listOrdered);\n\n    if (kind === types.listUnordered ? !self.containerState.marker || code === self.containerState.marker : asciiDigit(code)) {\n      if (!self.containerState.type) {\n        self.containerState.type = kind;\n        effects.enter(kind, {\n          _container: true\n        });\n      }\n\n      if (kind === types.listUnordered) {\n        effects.enter(types.listItemPrefix);\n        return code === codes.asterisk || code === codes.dash ? effects.check(thematicBreak, nok, atMarker)(code) : atMarker(code);\n      }\n\n      if (!self.interrupt || code === codes.digit1) {\n        effects.enter(types.listItemPrefix);\n        effects.enter(types.listItemValue);\n        return inside(code);\n      }\n    }\n\n    return nok(code);\n  }\n  /** @type {State} */\n\n\n  function inside(code) {\n    assert(self.containerState, 'expected state');\n\n    if (asciiDigit(code) && ++size < constants.listItemValueSizeMax) {\n      effects.consume(code);\n      return inside;\n    }\n\n    if ((!self.interrupt || size < 2) && (self.containerState.marker ? code === self.containerState.marker : code === codes.rightParenthesis || code === codes.dot)) {\n      effects.exit(types.listItemValue);\n      return atMarker(code);\n    }\n\n    return nok(code);\n  }\n  /**\n   * @type {State}\n   **/\n\n\n  function atMarker(code) {\n    assert(self.containerState, 'expected state');\n    assert(code !== codes.eof, 'eof (`null`) is not a marker');\n    effects.enter(types.listItemMarker);\n    effects.consume(code);\n    effects.exit(types.listItemMarker);\n    self.containerState.marker = self.containerState.marker || code;\n    return effects.check(blankLine, // Can’t be empty when interrupting.\n    self.interrupt ? nok : onBlank, effects.attempt(listItemPrefixWhitespaceConstruct, endOfPrefix, otherPrefix));\n  }\n  /** @type {State} */\n\n\n  function onBlank(code) {\n    assert(self.containerState, 'expected state');\n    self.containerState.initialBlankLine = true;\n    initialSize++;\n    return endOfPrefix(code);\n  }\n  /** @type {State} */\n\n\n  function otherPrefix(code) {\n    if (markdownSpace(code)) {\n      effects.enter(types.listItemPrefixWhitespace);\n      effects.consume(code);\n      effects.exit(types.listItemPrefixWhitespace);\n      return endOfPrefix;\n    }\n\n    return nok(code);\n  }\n  /** @type {State} */\n\n\n  function endOfPrefix(code) {\n    assert(self.containerState, 'expected state');\n    self.containerState.size = initialSize + self.sliceSerialize(effects.exit(types.listItemPrefix), true).length;\n    return ok(code);\n  }\n}\n/**\n * @type {Tokenizer}\n * @this {TokenizeContext}\n */\n\n\nfunction tokenizeListContinuation(effects, ok, nok) {\n  const self = this;\n  assert(self.containerState, 'expected state');\n  self.containerState._closeFlow = undefined;\n  return effects.check(blankLine, onBlank, notBlank);\n  /** @type {State} */\n\n  function onBlank(code) {\n    assert(self.containerState, 'expected state');\n    assert(typeof self.containerState.size === 'number', 'expected size');\n    self.containerState.furtherBlankLines = self.containerState.furtherBlankLines || self.containerState.initialBlankLine; // We have a blank line.\n    // Still, try to consume at most the items size.\n\n    return factorySpace(effects, ok, types.listItemIndent, self.containerState.size + 1)(code);\n  }\n  /** @type {State} */\n\n\n  function notBlank(code) {\n    assert(self.containerState, 'expected state');\n\n    if (self.containerState.furtherBlankLines || !markdownSpace(code)) {\n      self.containerState.furtherBlankLines = undefined;\n      self.containerState.initialBlankLine = undefined;\n      return notInCurrentItem(code);\n    }\n\n    self.containerState.furtherBlankLines = undefined;\n    self.containerState.initialBlankLine = undefined;\n    return effects.attempt(indentConstruct, ok, notInCurrentItem)(code);\n  }\n  /** @type {State} */\n\n\n  function notInCurrentItem(code) {\n    assert(self.containerState, 'expected state'); // While we do continue, we signal that the flow should be closed.\n\n    self.containerState._closeFlow = true; // As we’re closing flow, we’re no longer interrupting.\n\n    self.interrupt = undefined; // Always populated by defaults.\n\n    assert(self.parser.constructs.disable.null, 'expected `disable.null` to be populated');\n    return factorySpace(effects, effects.attempt(list, ok, nok), types.linePrefix, self.parser.constructs.disable.null.includes('codeIndented') ? undefined : constants.tabSize)(code);\n  }\n}\n/**\n * @type {Tokenizer}\n * @this {TokenizeContext}\n */\n\n\nfunction tokenizeIndent(effects, ok, nok) {\n  const self = this;\n  assert(self.containerState, 'expected state');\n  assert(typeof self.containerState.size === 'number', 'expected size');\n  return factorySpace(effects, afterPrefix, types.listItemIndent, self.containerState.size + 1);\n  /** @type {State} */\n\n  function afterPrefix(code) {\n    assert(self.containerState, 'expected state');\n    const tail = self.events[self.events.length - 1];\n    return tail && tail[1].type === types.listItemIndent && tail[2].sliceSerialize(tail[1], true).length === self.containerState.size ? ok(code) : nok(code);\n  }\n}\n/**\n * @type {Exiter}\n * @this {TokenizeContext}\n */\n\n\nfunction tokenizeListEnd(effects) {\n  assert(this.containerState, 'expected state');\n  assert(typeof this.containerState.type === 'string', 'expected type');\n  effects.exit(this.containerState.type);\n}\n/**\n * @type {Tokenizer}\n * @this {TokenizeContext}\n */\n\n\nfunction tokenizeListItemPrefixWhitespace(effects, ok, nok) {\n  const self = this; // Always populated by defaults.\n\n  assert(self.parser.constructs.disable.null, 'expected `disable.null` to be populated');\n  return factorySpace(effects, afterPrefix, types.listItemPrefixWhitespace, self.parser.constructs.disable.null.includes('codeIndented') ? undefined : constants.tabSize + 1);\n  /** @type {State} */\n\n  function afterPrefix(code) {\n    const tail = self.events[self.events.length - 1];\n    return !markdownSpace(code) && tail && tail[1].type === types.listItemPrefixWhitespace ? ok(code) : nok(code);\n  }\n}","map":{"version":3,"sources":["D:/com lab/react/keerthana/auth2/AuthInMern/client/node_modules/micromark-core-commonmark/dev/lib/list.js"],"names":["factorySpace","asciiDigit","markdownSpace","codes","constants","types","ok","assert","blankLine","thematicBreak","list","name","tokenize","tokenizeListStart","continuation","tokenizeListContinuation","exit","tokenizeListEnd","listItemPrefixWhitespaceConstruct","tokenizeListItemPrefixWhitespace","partial","indentConstruct","tokenizeIndent","effects","nok","self","tail","events","length","initialSize","type","linePrefix","sliceSerialize","size","start","code","containerState","kind","asterisk","plusSign","dash","listUnordered","listOrdered","marker","enter","_container","listItemPrefix","check","atMarker","interrupt","digit1","listItemValue","inside","listItemValueSizeMax","consume","rightParenthesis","dot","eof","listItemMarker","onBlank","attempt","endOfPrefix","otherPrefix","initialBlankLine","listItemPrefixWhitespace","_closeFlow","undefined","notBlank","furtherBlankLines","listItemIndent","notInCurrentItem","parser","constructs","disable","null","includes","tabSize","afterPrefix"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAAQA,YAAR,QAA2B,yBAA3B;AACA,SAAQC,UAAR,EAAoBC,aAApB,QAAwC,0BAAxC;AACA,SAAQC,KAAR,QAAoB,gCAApB;AACA,SAAQC,SAAR,QAAwB,oCAAxB;AACA,SAAQC,KAAR,QAAoB,gCAApB;AACA,SAAQC,EAAE,IAAIC,MAAd,QAA2B,YAA3B;AACA,SAAQC,SAAR,QAAwB,iBAAxB;AACA,SAAQC,aAAR,QAA4B,qBAA5B;AAEA;;AACA,OAAO,MAAMC,IAAI,GAAG;AAClBC,EAAAA,IAAI,EAAE,MADY;AAElBC,EAAAA,QAAQ,EAAEC,iBAFQ;AAGlBC,EAAAA,YAAY,EAAE;AAACF,IAAAA,QAAQ,EAAEG;AAAX,GAHI;AAIlBC,EAAAA,IAAI,EAAEC;AAJY,CAAb;AAOP;;AACA,MAAMC,iCAAiC,GAAG;AACxCN,EAAAA,QAAQ,EAAEO,gCAD8B;AAExCC,EAAAA,OAAO,EAAE;AAF+B,CAA1C;AAKA;;AACA,MAAMC,eAAe,GAAG;AAACT,EAAAA,QAAQ,EAAEU,cAAX;AAA2BF,EAAAA,OAAO,EAAE;AAApC,CAAxB,C,CAEA;AACA;;AAEA;AACA;AACA;AACA;;AACA,SAASP,iBAAT,CAA2BU,OAA3B,EAAoCjB,EAApC,EAAwCkB,GAAxC,EAA6C;AAC3C,QAAMC,IAAI,GAAG,IAAb;AACA,QAAMC,IAAI,GAAGD,IAAI,CAACE,MAAL,CAAYF,IAAI,CAACE,MAAL,CAAYC,MAAZ,GAAqB,CAAjC,CAAb;AACA,MAAIC,WAAW,GACbH,IAAI,IAAIA,IAAI,CAAC,CAAD,CAAJ,CAAQI,IAAR,KAAiBzB,KAAK,CAAC0B,UAA/B,GACIL,IAAI,CAAC,CAAD,CAAJ,CAAQM,cAAR,CAAuBN,IAAI,CAAC,CAAD,CAA3B,EAAgC,IAAhC,EAAsCE,MAD1C,GAEI,CAHN;AAIA,MAAIK,IAAI,GAAG,CAAX;AAEA,SAAOC,KAAP;AAEA;;AACA,WAASA,KAAT,CAAeC,IAAf,EAAqB;AACnB5B,IAAAA,MAAM,CAACkB,IAAI,CAACW,cAAN,EAAsB,gBAAtB,CAAN;AACA,UAAMC,IAAI,GACRZ,IAAI,CAACW,cAAL,CAAoBN,IAApB,KACCK,IAAI,KAAKhC,KAAK,CAACmC,QAAf,IAA2BH,IAAI,KAAKhC,KAAK,CAACoC,QAA1C,IAAsDJ,IAAI,KAAKhC,KAAK,CAACqC,IAArE,GACGnC,KAAK,CAACoC,aADT,GAEGpC,KAAK,CAACqC,WAHV,CADF;;AAMA,QACEL,IAAI,KAAKhC,KAAK,CAACoC,aAAf,GACI,CAAChB,IAAI,CAACW,cAAL,CAAoBO,MAArB,IAA+BR,IAAI,KAAKV,IAAI,CAACW,cAAL,CAAoBO,MADhE,GAEI1C,UAAU,CAACkC,IAAD,CAHhB,EAIE;AACA,UAAI,CAACV,IAAI,CAACW,cAAL,CAAoBN,IAAzB,EAA+B;AAC7BL,QAAAA,IAAI,CAACW,cAAL,CAAoBN,IAApB,GAA2BO,IAA3B;AACAd,QAAAA,OAAO,CAACqB,KAAR,CAAcP,IAAd,EAAoB;AAACQ,UAAAA,UAAU,EAAE;AAAb,SAApB;AACD;;AAED,UAAIR,IAAI,KAAKhC,KAAK,CAACoC,aAAnB,EAAkC;AAChClB,QAAAA,OAAO,CAACqB,KAAR,CAAcvC,KAAK,CAACyC,cAApB;AACA,eAAOX,IAAI,KAAKhC,KAAK,CAACmC,QAAf,IAA2BH,IAAI,KAAKhC,KAAK,CAACqC,IAA1C,GACHjB,OAAO,CAACwB,KAAR,CAActC,aAAd,EAA6Be,GAA7B,EAAkCwB,QAAlC,EAA4Cb,IAA5C,CADG,GAEHa,QAAQ,CAACb,IAAD,CAFZ;AAGD;;AAED,UAAI,CAACV,IAAI,CAACwB,SAAN,IAAmBd,IAAI,KAAKhC,KAAK,CAAC+C,MAAtC,EAA8C;AAC5C3B,QAAAA,OAAO,CAACqB,KAAR,CAAcvC,KAAK,CAACyC,cAApB;AACAvB,QAAAA,OAAO,CAACqB,KAAR,CAAcvC,KAAK,CAAC8C,aAApB;AACA,eAAOC,MAAM,CAACjB,IAAD,CAAb;AACD;AACF;;AAED,WAAOX,GAAG,CAACW,IAAD,CAAV;AACD;AAED;;;AACA,WAASiB,MAAT,CAAgBjB,IAAhB,EAAsB;AACpB5B,IAAAA,MAAM,CAACkB,IAAI,CAACW,cAAN,EAAsB,gBAAtB,CAAN;;AACA,QAAInC,UAAU,CAACkC,IAAD,CAAV,IAAoB,EAAEF,IAAF,GAAS7B,SAAS,CAACiD,oBAA3C,EAAiE;AAC/D9B,MAAAA,OAAO,CAAC+B,OAAR,CAAgBnB,IAAhB;AACA,aAAOiB,MAAP;AACD;;AAED,QACE,CAAC,CAAC3B,IAAI,CAACwB,SAAN,IAAmBhB,IAAI,GAAG,CAA3B,MACCR,IAAI,CAACW,cAAL,CAAoBO,MAApB,GACGR,IAAI,KAAKV,IAAI,CAACW,cAAL,CAAoBO,MADhC,GAEGR,IAAI,KAAKhC,KAAK,CAACoD,gBAAf,IAAmCpB,IAAI,KAAKhC,KAAK,CAACqD,GAHtD,CADF,EAKE;AACAjC,MAAAA,OAAO,CAACP,IAAR,CAAaX,KAAK,CAAC8C,aAAnB;AACA,aAAOH,QAAQ,CAACb,IAAD,CAAf;AACD;;AAED,WAAOX,GAAG,CAACW,IAAD,CAAV;AACD;AAED;AACF;AACA;;;AACE,WAASa,QAAT,CAAkBb,IAAlB,EAAwB;AACtB5B,IAAAA,MAAM,CAACkB,IAAI,CAACW,cAAN,EAAsB,gBAAtB,CAAN;AACA7B,IAAAA,MAAM,CAAC4B,IAAI,KAAKhC,KAAK,CAACsD,GAAhB,EAAqB,8BAArB,CAAN;AACAlC,IAAAA,OAAO,CAACqB,KAAR,CAAcvC,KAAK,CAACqD,cAApB;AACAnC,IAAAA,OAAO,CAAC+B,OAAR,CAAgBnB,IAAhB;AACAZ,IAAAA,OAAO,CAACP,IAAR,CAAaX,KAAK,CAACqD,cAAnB;AACAjC,IAAAA,IAAI,CAACW,cAAL,CAAoBO,MAApB,GAA6BlB,IAAI,CAACW,cAAL,CAAoBO,MAApB,IAA8BR,IAA3D;AACA,WAAOZ,OAAO,CAACwB,KAAR,CACLvC,SADK,EAEL;AACAiB,IAAAA,IAAI,CAACwB,SAAL,GAAiBzB,GAAjB,GAAuBmC,OAHlB,EAILpC,OAAO,CAACqC,OAAR,CACE1C,iCADF,EAEE2C,WAFF,EAGEC,WAHF,CAJK,CAAP;AAUD;AAED;;;AACA,WAASH,OAAT,CAAiBxB,IAAjB,EAAuB;AACrB5B,IAAAA,MAAM,CAACkB,IAAI,CAACW,cAAN,EAAsB,gBAAtB,CAAN;AACAX,IAAAA,IAAI,CAACW,cAAL,CAAoB2B,gBAApB,GAAuC,IAAvC;AACAlC,IAAAA,WAAW;AACX,WAAOgC,WAAW,CAAC1B,IAAD,CAAlB;AACD;AAED;;;AACA,WAAS2B,WAAT,CAAqB3B,IAArB,EAA2B;AACzB,QAAIjC,aAAa,CAACiC,IAAD,CAAjB,EAAyB;AACvBZ,MAAAA,OAAO,CAACqB,KAAR,CAAcvC,KAAK,CAAC2D,wBAApB;AACAzC,MAAAA,OAAO,CAAC+B,OAAR,CAAgBnB,IAAhB;AACAZ,MAAAA,OAAO,CAACP,IAAR,CAAaX,KAAK,CAAC2D,wBAAnB;AACA,aAAOH,WAAP;AACD;;AAED,WAAOrC,GAAG,CAACW,IAAD,CAAV;AACD;AAED;;;AACA,WAAS0B,WAAT,CAAqB1B,IAArB,EAA2B;AACzB5B,IAAAA,MAAM,CAACkB,IAAI,CAACW,cAAN,EAAsB,gBAAtB,CAAN;AACAX,IAAAA,IAAI,CAACW,cAAL,CAAoBH,IAApB,GACEJ,WAAW,GACXJ,IAAI,CAACO,cAAL,CAAoBT,OAAO,CAACP,IAAR,CAAaX,KAAK,CAACyC,cAAnB,CAApB,EAAwD,IAAxD,EAA8DlB,MAFhE;AAGA,WAAOtB,EAAE,CAAC6B,IAAD,CAAT;AACD;AACF;AAED;AACA;AACA;AACA;;;AACA,SAASpB,wBAAT,CAAkCQ,OAAlC,EAA2CjB,EAA3C,EAA+CkB,GAA/C,EAAoD;AAClD,QAAMC,IAAI,GAAG,IAAb;AAEAlB,EAAAA,MAAM,CAACkB,IAAI,CAACW,cAAN,EAAsB,gBAAtB,CAAN;AACAX,EAAAA,IAAI,CAACW,cAAL,CAAoB6B,UAApB,GAAiCC,SAAjC;AAEA,SAAO3C,OAAO,CAACwB,KAAR,CAAcvC,SAAd,EAAyBmD,OAAzB,EAAkCQ,QAAlC,CAAP;AAEA;;AACA,WAASR,OAAT,CAAiBxB,IAAjB,EAAuB;AACrB5B,IAAAA,MAAM,CAACkB,IAAI,CAACW,cAAN,EAAsB,gBAAtB,CAAN;AACA7B,IAAAA,MAAM,CAAC,OAAOkB,IAAI,CAACW,cAAL,CAAoBH,IAA3B,KAAoC,QAArC,EAA+C,eAA/C,CAAN;AACAR,IAAAA,IAAI,CAACW,cAAL,CAAoBgC,iBAApB,GACE3C,IAAI,CAACW,cAAL,CAAoBgC,iBAApB,IACA3C,IAAI,CAACW,cAAL,CAAoB2B,gBAFtB,CAHqB,CAOrB;AACA;;AACA,WAAO/D,YAAY,CACjBuB,OADiB,EAEjBjB,EAFiB,EAGjBD,KAAK,CAACgE,cAHW,EAIjB5C,IAAI,CAACW,cAAL,CAAoBH,IAApB,GAA2B,CAJV,CAAZ,CAKLE,IALK,CAAP;AAMD;AAED;;;AACA,WAASgC,QAAT,CAAkBhC,IAAlB,EAAwB;AACtB5B,IAAAA,MAAM,CAACkB,IAAI,CAACW,cAAN,EAAsB,gBAAtB,CAAN;;AACA,QAAIX,IAAI,CAACW,cAAL,CAAoBgC,iBAApB,IAAyC,CAAClE,aAAa,CAACiC,IAAD,CAA3D,EAAmE;AACjEV,MAAAA,IAAI,CAACW,cAAL,CAAoBgC,iBAApB,GAAwCF,SAAxC;AACAzC,MAAAA,IAAI,CAACW,cAAL,CAAoB2B,gBAApB,GAAuCG,SAAvC;AACA,aAAOI,gBAAgB,CAACnC,IAAD,CAAvB;AACD;;AAEDV,IAAAA,IAAI,CAACW,cAAL,CAAoBgC,iBAApB,GAAwCF,SAAxC;AACAzC,IAAAA,IAAI,CAACW,cAAL,CAAoB2B,gBAApB,GAAuCG,SAAvC;AACA,WAAO3C,OAAO,CAACqC,OAAR,CAAgBvC,eAAhB,EAAiCf,EAAjC,EAAqCgE,gBAArC,EAAuDnC,IAAvD,CAAP;AACD;AAED;;;AACA,WAASmC,gBAAT,CAA0BnC,IAA1B,EAAgC;AAC9B5B,IAAAA,MAAM,CAACkB,IAAI,CAACW,cAAN,EAAsB,gBAAtB,CAAN,CAD8B,CAE9B;;AACAX,IAAAA,IAAI,CAACW,cAAL,CAAoB6B,UAApB,GAAiC,IAAjC,CAH8B,CAI9B;;AACAxC,IAAAA,IAAI,CAACwB,SAAL,GAAiBiB,SAAjB,CAL8B,CAM9B;;AACA3D,IAAAA,MAAM,CACJkB,IAAI,CAAC8C,MAAL,CAAYC,UAAZ,CAAuBC,OAAvB,CAA+BC,IAD3B,EAEJ,yCAFI,CAAN;AAIA,WAAO1E,YAAY,CACjBuB,OADiB,EAEjBA,OAAO,CAACqC,OAAR,CAAgBlD,IAAhB,EAAsBJ,EAAtB,EAA0BkB,GAA1B,CAFiB,EAGjBnB,KAAK,CAAC0B,UAHW,EAIjBN,IAAI,CAAC8C,MAAL,CAAYC,UAAZ,CAAuBC,OAAvB,CAA+BC,IAA/B,CAAoCC,QAApC,CAA6C,cAA7C,IACIT,SADJ,GAEI9D,SAAS,CAACwE,OANG,CAAZ,CAOLzC,IAPK,CAAP;AAQD;AACF;AAED;AACA;AACA;AACA;;;AACA,SAASb,cAAT,CAAwBC,OAAxB,EAAiCjB,EAAjC,EAAqCkB,GAArC,EAA0C;AACxC,QAAMC,IAAI,GAAG,IAAb;AAEAlB,EAAAA,MAAM,CAACkB,IAAI,CAACW,cAAN,EAAsB,gBAAtB,CAAN;AACA7B,EAAAA,MAAM,CAAC,OAAOkB,IAAI,CAACW,cAAL,CAAoBH,IAA3B,KAAoC,QAArC,EAA+C,eAA/C,CAAN;AAEA,SAAOjC,YAAY,CACjBuB,OADiB,EAEjBsD,WAFiB,EAGjBxE,KAAK,CAACgE,cAHW,EAIjB5C,IAAI,CAACW,cAAL,CAAoBH,IAApB,GAA2B,CAJV,CAAnB;AAOA;;AACA,WAAS4C,WAAT,CAAqB1C,IAArB,EAA2B;AACzB5B,IAAAA,MAAM,CAACkB,IAAI,CAACW,cAAN,EAAsB,gBAAtB,CAAN;AACA,UAAMV,IAAI,GAAGD,IAAI,CAACE,MAAL,CAAYF,IAAI,CAACE,MAAL,CAAYC,MAAZ,GAAqB,CAAjC,CAAb;AACA,WAAOF,IAAI,IACTA,IAAI,CAAC,CAAD,CAAJ,CAAQI,IAAR,KAAiBzB,KAAK,CAACgE,cADlB,IAEL3C,IAAI,CAAC,CAAD,CAAJ,CAAQM,cAAR,CAAuBN,IAAI,CAAC,CAAD,CAA3B,EAAgC,IAAhC,EAAsCE,MAAtC,KAAiDH,IAAI,CAACW,cAAL,CAAoBH,IAFhE,GAGH3B,EAAE,CAAC6B,IAAD,CAHC,GAIHX,GAAG,CAACW,IAAD,CAJP;AAKD;AACF;AAED;AACA;AACA;AACA;;;AACA,SAASlB,eAAT,CAAyBM,OAAzB,EAAkC;AAChChB,EAAAA,MAAM,CAAC,KAAK6B,cAAN,EAAsB,gBAAtB,CAAN;AACA7B,EAAAA,MAAM,CAAC,OAAO,KAAK6B,cAAL,CAAoBN,IAA3B,KAAoC,QAArC,EAA+C,eAA/C,CAAN;AACAP,EAAAA,OAAO,CAACP,IAAR,CAAa,KAAKoB,cAAL,CAAoBN,IAAjC;AACD;AAED;AACA;AACA;AACA;;;AACA,SAASX,gCAAT,CAA0CI,OAA1C,EAAmDjB,EAAnD,EAAuDkB,GAAvD,EAA4D;AAC1D,QAAMC,IAAI,GAAG,IAAb,CAD0D,CAG1D;;AACAlB,EAAAA,MAAM,CACJkB,IAAI,CAAC8C,MAAL,CAAYC,UAAZ,CAAuBC,OAAvB,CAA+BC,IAD3B,EAEJ,yCAFI,CAAN;AAKA,SAAO1E,YAAY,CACjBuB,OADiB,EAEjBsD,WAFiB,EAGjBxE,KAAK,CAAC2D,wBAHW,EAIjBvC,IAAI,CAAC8C,MAAL,CAAYC,UAAZ,CAAuBC,OAAvB,CAA+BC,IAA/B,CAAoCC,QAApC,CAA6C,cAA7C,IACIT,SADJ,GAEI9D,SAAS,CAACwE,OAAV,GAAoB,CANP,CAAnB;AASA;;AACA,WAASC,WAAT,CAAqB1C,IAArB,EAA2B;AACzB,UAAMT,IAAI,GAAGD,IAAI,CAACE,MAAL,CAAYF,IAAI,CAACE,MAAL,CAAYC,MAAZ,GAAqB,CAAjC,CAAb;AAEA,WAAO,CAAC1B,aAAa,CAACiC,IAAD,CAAd,IACLT,IADK,IAELA,IAAI,CAAC,CAAD,CAAJ,CAAQI,IAAR,KAAiBzB,KAAK,CAAC2D,wBAFlB,GAGH1D,EAAE,CAAC6B,IAAD,CAHC,GAIHX,GAAG,CAACW,IAAD,CAJP;AAKD;AACF","sourcesContent":["/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ContainerState} ContainerState\n * @typedef {import('micromark-util-types').Exiter} Exiter\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {asciiDigit, markdownSpace} from 'micromark-util-character'\nimport {codes} from 'micromark-util-symbol/codes.js'\nimport {constants} from 'micromark-util-symbol/constants.js'\nimport {types} from 'micromark-util-symbol/types.js'\nimport {ok as assert} from 'uvu/assert'\nimport {blankLine} from './blank-line.js'\nimport {thematicBreak} from './thematic-break.js'\n\n/** @type {Construct} */\nexport const list = {\n  name: 'list',\n  tokenize: tokenizeListStart,\n  continuation: {tokenize: tokenizeListContinuation},\n  exit: tokenizeListEnd\n}\n\n/** @type {Construct} */\nconst listItemPrefixWhitespaceConstruct = {\n  tokenize: tokenizeListItemPrefixWhitespace,\n  partial: true\n}\n\n/** @type {Construct} */\nconst indentConstruct = {tokenize: tokenizeIndent, partial: true}\n\n// To do: `markdown-rs` parses list items on their own and later stitches them\n// together.\n\n/**\n * @type {Tokenizer}\n * @this {TokenizeContext}\n */\nfunction tokenizeListStart(effects, ok, nok) {\n  const self = this\n  const tail = self.events[self.events.length - 1]\n  let initialSize =\n    tail && tail[1].type === types.linePrefix\n      ? tail[2].sliceSerialize(tail[1], true).length\n      : 0\n  let size = 0\n\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    assert(self.containerState, 'expected state')\n    const kind =\n      self.containerState.type ||\n      (code === codes.asterisk || code === codes.plusSign || code === codes.dash\n        ? types.listUnordered\n        : types.listOrdered)\n\n    if (\n      kind === types.listUnordered\n        ? !self.containerState.marker || code === self.containerState.marker\n        : asciiDigit(code)\n    ) {\n      if (!self.containerState.type) {\n        self.containerState.type = kind\n        effects.enter(kind, {_container: true})\n      }\n\n      if (kind === types.listUnordered) {\n        effects.enter(types.listItemPrefix)\n        return code === codes.asterisk || code === codes.dash\n          ? effects.check(thematicBreak, nok, atMarker)(code)\n          : atMarker(code)\n      }\n\n      if (!self.interrupt || code === codes.digit1) {\n        effects.enter(types.listItemPrefix)\n        effects.enter(types.listItemValue)\n        return inside(code)\n      }\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function inside(code) {\n    assert(self.containerState, 'expected state')\n    if (asciiDigit(code) && ++size < constants.listItemValueSizeMax) {\n      effects.consume(code)\n      return inside\n    }\n\n    if (\n      (!self.interrupt || size < 2) &&\n      (self.containerState.marker\n        ? code === self.containerState.marker\n        : code === codes.rightParenthesis || code === codes.dot)\n    ) {\n      effects.exit(types.listItemValue)\n      return atMarker(code)\n    }\n\n    return nok(code)\n  }\n\n  /**\n   * @type {State}\n   **/\n  function atMarker(code) {\n    assert(self.containerState, 'expected state')\n    assert(code !== codes.eof, 'eof (`null`) is not a marker')\n    effects.enter(types.listItemMarker)\n    effects.consume(code)\n    effects.exit(types.listItemMarker)\n    self.containerState.marker = self.containerState.marker || code\n    return effects.check(\n      blankLine,\n      // Can’t be empty when interrupting.\n      self.interrupt ? nok : onBlank,\n      effects.attempt(\n        listItemPrefixWhitespaceConstruct,\n        endOfPrefix,\n        otherPrefix\n      )\n    )\n  }\n\n  /** @type {State} */\n  function onBlank(code) {\n    assert(self.containerState, 'expected state')\n    self.containerState.initialBlankLine = true\n    initialSize++\n    return endOfPrefix(code)\n  }\n\n  /** @type {State} */\n  function otherPrefix(code) {\n    if (markdownSpace(code)) {\n      effects.enter(types.listItemPrefixWhitespace)\n      effects.consume(code)\n      effects.exit(types.listItemPrefixWhitespace)\n      return endOfPrefix\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function endOfPrefix(code) {\n    assert(self.containerState, 'expected state')\n    self.containerState.size =\n      initialSize +\n      self.sliceSerialize(effects.exit(types.listItemPrefix), true).length\n    return ok(code)\n  }\n}\n\n/**\n * @type {Tokenizer}\n * @this {TokenizeContext}\n */\nfunction tokenizeListContinuation(effects, ok, nok) {\n  const self = this\n\n  assert(self.containerState, 'expected state')\n  self.containerState._closeFlow = undefined\n\n  return effects.check(blankLine, onBlank, notBlank)\n\n  /** @type {State} */\n  function onBlank(code) {\n    assert(self.containerState, 'expected state')\n    assert(typeof self.containerState.size === 'number', 'expected size')\n    self.containerState.furtherBlankLines =\n      self.containerState.furtherBlankLines ||\n      self.containerState.initialBlankLine\n\n    // We have a blank line.\n    // Still, try to consume at most the items size.\n    return factorySpace(\n      effects,\n      ok,\n      types.listItemIndent,\n      self.containerState.size + 1\n    )(code)\n  }\n\n  /** @type {State} */\n  function notBlank(code) {\n    assert(self.containerState, 'expected state')\n    if (self.containerState.furtherBlankLines || !markdownSpace(code)) {\n      self.containerState.furtherBlankLines = undefined\n      self.containerState.initialBlankLine = undefined\n      return notInCurrentItem(code)\n    }\n\n    self.containerState.furtherBlankLines = undefined\n    self.containerState.initialBlankLine = undefined\n    return effects.attempt(indentConstruct, ok, notInCurrentItem)(code)\n  }\n\n  /** @type {State} */\n  function notInCurrentItem(code) {\n    assert(self.containerState, 'expected state')\n    // While we do continue, we signal that the flow should be closed.\n    self.containerState._closeFlow = true\n    // As we’re closing flow, we’re no longer interrupting.\n    self.interrupt = undefined\n    // Always populated by defaults.\n    assert(\n      self.parser.constructs.disable.null,\n      'expected `disable.null` to be populated'\n    )\n    return factorySpace(\n      effects,\n      effects.attempt(list, ok, nok),\n      types.linePrefix,\n      self.parser.constructs.disable.null.includes('codeIndented')\n        ? undefined\n        : constants.tabSize\n    )(code)\n  }\n}\n\n/**\n * @type {Tokenizer}\n * @this {TokenizeContext}\n */\nfunction tokenizeIndent(effects, ok, nok) {\n  const self = this\n\n  assert(self.containerState, 'expected state')\n  assert(typeof self.containerState.size === 'number', 'expected size')\n\n  return factorySpace(\n    effects,\n    afterPrefix,\n    types.listItemIndent,\n    self.containerState.size + 1\n  )\n\n  /** @type {State} */\n  function afterPrefix(code) {\n    assert(self.containerState, 'expected state')\n    const tail = self.events[self.events.length - 1]\n    return tail &&\n      tail[1].type === types.listItemIndent &&\n      tail[2].sliceSerialize(tail[1], true).length === self.containerState.size\n      ? ok(code)\n      : nok(code)\n  }\n}\n\n/**\n * @type {Exiter}\n * @this {TokenizeContext}\n */\nfunction tokenizeListEnd(effects) {\n  assert(this.containerState, 'expected state')\n  assert(typeof this.containerState.type === 'string', 'expected type')\n  effects.exit(this.containerState.type)\n}\n\n/**\n * @type {Tokenizer}\n * @this {TokenizeContext}\n */\nfunction tokenizeListItemPrefixWhitespace(effects, ok, nok) {\n  const self = this\n\n  // Always populated by defaults.\n  assert(\n    self.parser.constructs.disable.null,\n    'expected `disable.null` to be populated'\n  )\n\n  return factorySpace(\n    effects,\n    afterPrefix,\n    types.listItemPrefixWhitespace,\n    self.parser.constructs.disable.null.includes('codeIndented')\n      ? undefined\n      : constants.tabSize + 1\n  )\n\n  /** @type {State} */\n  function afterPrefix(code) {\n    const tail = self.events[self.events.length - 1]\n\n    return !markdownSpace(code) &&\n      tail &&\n      tail[1].type === types.listItemPrefixWhitespace\n      ? ok(code)\n      : nok(code)\n  }\n}\n"]},"metadata":{},"sourceType":"module"}