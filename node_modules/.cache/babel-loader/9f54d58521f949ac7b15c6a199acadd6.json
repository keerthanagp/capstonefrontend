{"ast":null,"code":"/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\nimport { push, splice } from 'micromark-util-chunked';\nimport { classifyCharacter } from 'micromark-util-classify-character';\nimport { resolveAll } from 'micromark-util-resolve-all';\nimport { codes } from 'micromark-util-symbol/codes.js';\nimport { constants } from 'micromark-util-symbol/constants.js';\nimport { types } from 'micromark-util-symbol/types.js';\nimport { ok as assert } from 'uvu/assert';\n/** @type {Construct} */\n\nexport const attention = {\n  name: 'attention',\n  tokenize: tokenizeAttention,\n  resolveAll: resolveAllAttention\n};\n/**\n * Take all events and resolve attention to emphasis or strong.\n *\n * @type {Resolver}\n */\n\nfunction resolveAllAttention(events, context) {\n  let index = -1;\n  /** @type {number} */\n\n  let open;\n  /** @type {Token} */\n\n  let group;\n  /** @type {Token} */\n\n  let text;\n  /** @type {Token} */\n\n  let openingSequence;\n  /** @type {Token} */\n\n  let closingSequence;\n  /** @type {number} */\n\n  let use;\n  /** @type {Array<Event>} */\n\n  let nextEvents;\n  /** @type {number} */\n\n  let offset; // Walk through all events.\n  //\n  // Note: performance of this is fine on an mb of normal markdown, but it’s\n  // a bottleneck for malicious stuff.\n\n  while (++index < events.length) {\n    // Find a token that can close.\n    if (events[index][0] === 'enter' && events[index][1].type === 'attentionSequence' && events[index][1]._close) {\n      open = index; // Now walk back to find an opener.\n\n      while (open--) {\n        // Find a token that can open the closer.\n        if (events[open][0] === 'exit' && events[open][1].type === 'attentionSequence' && events[open][1]._open && // If the markers are the same:\n        context.sliceSerialize(events[open][1]).charCodeAt(0) === context.sliceSerialize(events[index][1]).charCodeAt(0)) {\n          // If the opening can close or the closing can open,\n          // and the close size *is not* a multiple of three,\n          // but the sum of the opening and closing size *is* multiple of three,\n          // then don’t match.\n          if ((events[open][1]._close || events[index][1]._open) && (events[index][1].end.offset - events[index][1].start.offset) % 3 && !((events[open][1].end.offset - events[open][1].start.offset + events[index][1].end.offset - events[index][1].start.offset) % 3)) {\n            continue;\n          } // Number of markers to use from the sequence.\n\n\n          use = events[open][1].end.offset - events[open][1].start.offset > 1 && events[index][1].end.offset - events[index][1].start.offset > 1 ? 2 : 1;\n          const start = Object.assign({}, events[open][1].end);\n          const end = Object.assign({}, events[index][1].start);\n          movePoint(start, -use);\n          movePoint(end, use);\n          openingSequence = {\n            type: use > 1 ? types.strongSequence : types.emphasisSequence,\n            start,\n            end: Object.assign({}, events[open][1].end)\n          };\n          closingSequence = {\n            type: use > 1 ? types.strongSequence : types.emphasisSequence,\n            start: Object.assign({}, events[index][1].start),\n            end\n          };\n          text = {\n            type: use > 1 ? types.strongText : types.emphasisText,\n            start: Object.assign({}, events[open][1].end),\n            end: Object.assign({}, events[index][1].start)\n          };\n          group = {\n            type: use > 1 ? types.strong : types.emphasis,\n            start: Object.assign({}, openingSequence.start),\n            end: Object.assign({}, closingSequence.end)\n          };\n          events[open][1].end = Object.assign({}, openingSequence.start);\n          events[index][1].start = Object.assign({}, closingSequence.end);\n          nextEvents = []; // If there are more markers in the opening, add them before.\n\n          if (events[open][1].end.offset - events[open][1].start.offset) {\n            nextEvents = push(nextEvents, [['enter', events[open][1], context], ['exit', events[open][1], context]]);\n          } // Opening.\n\n\n          nextEvents = push(nextEvents, [['enter', group, context], ['enter', openingSequence, context], ['exit', openingSequence, context], ['enter', text, context]]); // Always populated by defaults.\n\n          assert(context.parser.constructs.insideSpan.null, 'expected `insideSpan` to be populated'); // Between.\n\n          nextEvents = push(nextEvents, resolveAll(context.parser.constructs.insideSpan.null, events.slice(open + 1, index), context)); // Closing.\n\n          nextEvents = push(nextEvents, [['exit', text, context], ['enter', closingSequence, context], ['exit', closingSequence, context], ['exit', group, context]]); // If there are more markers in the closing, add them after.\n\n          if (events[index][1].end.offset - events[index][1].start.offset) {\n            offset = 2;\n            nextEvents = push(nextEvents, [['enter', events[index][1], context], ['exit', events[index][1], context]]);\n          } else {\n            offset = 0;\n          }\n\n          splice(events, open - 1, index - open + 3, nextEvents);\n          index = open + nextEvents.length - offset - 2;\n          break;\n        }\n      }\n    }\n  } // Remove remaining sequences.\n\n\n  index = -1;\n\n  while (++index < events.length) {\n    if (events[index][1].type === 'attentionSequence') {\n      events[index][1].type = 'data';\n    }\n  }\n\n  return events;\n}\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\n\n\nfunction tokenizeAttention(effects, ok) {\n  const attentionMarkers = this.parser.constructs.attentionMarkers.null;\n  const previous = this.previous;\n  const before = classifyCharacter(previous);\n  /** @type {NonNullable<Code>} */\n\n  let marker;\n  return start;\n  /**\n   * Before a sequence.\n   *\n   * ```markdown\n   * > | **\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n\n  function start(code) {\n    assert(code === codes.asterisk || code === codes.underscore, 'expected asterisk or underscore');\n    marker = code;\n    effects.enter('attentionSequence');\n    return inside(code);\n  }\n  /**\n   * In a sequence.\n   *\n   * ```markdown\n   * > | **\n   *     ^^\n   * ```\n   *\n   * @type {State}\n   */\n\n\n  function inside(code) {\n    if (code === marker) {\n      effects.consume(code);\n      return inside;\n    }\n\n    const token = effects.exit('attentionSequence'); // To do: next major: move this to resolver, just like `markdown-rs`.\n\n    const after = classifyCharacter(code); // Always populated by defaults.\n\n    assert(attentionMarkers, 'expected `attentionMarkers` to be populated');\n    const open = !after || after === constants.characterGroupPunctuation && before || attentionMarkers.includes(code);\n    const close = !before || before === constants.characterGroupPunctuation && after || attentionMarkers.includes(previous);\n    token._open = Boolean(marker === codes.asterisk ? open : open && (before || !close));\n    token._close = Boolean(marker === codes.asterisk ? close : close && (after || !open));\n    return ok(code);\n  }\n}\n/**\n * Move a point a bit.\n *\n * Note: `move` only works inside lines! It’s not possible to move past other\n * chunks (replacement characters, tabs, or line endings).\n *\n * @param {Point} point\n * @param {number} offset\n * @returns {void}\n */\n\n\nfunction movePoint(point, offset) {\n  point.column += offset;\n  point.offset += offset;\n  point._bufferIndex += offset;\n}","map":{"version":3,"sources":["D:/com lab/react/keerthana/auth2/AuthInMern/client/node_modules/micromark-core-commonmark/dev/lib/attention.js"],"names":["push","splice","classifyCharacter","resolveAll","codes","constants","types","ok","assert","attention","name","tokenize","tokenizeAttention","resolveAllAttention","events","context","index","open","group","text","openingSequence","closingSequence","use","nextEvents","offset","length","type","_close","_open","sliceSerialize","charCodeAt","end","start","Object","assign","movePoint","strongSequence","emphasisSequence","strongText","emphasisText","strong","emphasis","parser","constructs","insideSpan","null","slice","effects","attentionMarkers","previous","before","marker","code","asterisk","underscore","enter","inside","consume","token","exit","after","characterGroupPunctuation","includes","close","Boolean","point","column","_bufferIndex"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAAQA,IAAR,EAAcC,MAAd,QAA2B,wBAA3B;AACA,SAAQC,iBAAR,QAAgC,mCAAhC;AACA,SAAQC,UAAR,QAAyB,4BAAzB;AACA,SAAQC,KAAR,QAAoB,gCAApB;AACA,SAAQC,SAAR,QAAwB,oCAAxB;AACA,SAAQC,KAAR,QAAoB,gCAApB;AACA,SAAQC,EAAE,IAAIC,MAAd,QAA2B,YAA3B;AAEA;;AACA,OAAO,MAAMC,SAAS,GAAG;AACvBC,EAAAA,IAAI,EAAE,WADiB;AAEvBC,EAAAA,QAAQ,EAAEC,iBAFa;AAGvBT,EAAAA,UAAU,EAAEU;AAHW,CAAlB;AAMP;AACA;AACA;AACA;AACA;;AACA,SAASA,mBAAT,CAA6BC,MAA7B,EAAqCC,OAArC,EAA8C;AAC5C,MAAIC,KAAK,GAAG,CAAC,CAAb;AACA;;AACA,MAAIC,IAAJ;AACA;;AACA,MAAIC,KAAJ;AACA;;AACA,MAAIC,IAAJ;AACA;;AACA,MAAIC,eAAJ;AACA;;AACA,MAAIC,eAAJ;AACA;;AACA,MAAIC,GAAJ;AACA;;AACA,MAAIC,UAAJ;AACA;;AACA,MAAIC,MAAJ,CAjB4C,CAmB5C;AACA;AACA;AACA;;AACA,SAAO,EAAER,KAAF,GAAUF,MAAM,CAACW,MAAxB,EAAgC;AAC9B;AACA,QACEX,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,MAAqB,OAArB,IACAF,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBU,IAAjB,KAA0B,mBAD1B,IAEAZ,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBW,MAHnB,EAIE;AACAV,MAAAA,IAAI,GAAGD,KAAP,CADA,CAGA;;AACA,aAAOC,IAAI,EAAX,EAAe;AACb;AACA,YACEH,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,MAAoB,MAApB,IACAH,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,EAAgBS,IAAhB,KAAyB,mBADzB,IAEAZ,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,EAAgBW,KAFhB,IAGA;AACAb,QAAAA,OAAO,CAACc,cAAR,CAAuBf,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,CAAvB,EAAwCa,UAAxC,CAAmD,CAAnD,MACEf,OAAO,CAACc,cAAR,CAAuBf,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,CAAvB,EAAyCc,UAAzC,CAAoD,CAApD,CANJ,EAOE;AACA;AACA;AACA;AACA;AACA,cACE,CAAChB,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,EAAgBU,MAAhB,IAA0Bb,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBY,KAA5C,KACA,CAACd,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBe,GAAjB,CAAqBP,MAArB,GAA8BV,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBgB,KAAjB,CAAuBR,MAAtD,IAAgE,CADhE,IAEA,EACE,CAACV,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,EAAgBc,GAAhB,CAAoBP,MAApB,GACCV,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,EAAgBe,KAAhB,CAAsBR,MADvB,GAECV,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBe,GAAjB,CAAqBP,MAFtB,GAGCV,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBgB,KAAjB,CAAuBR,MAHzB,IAIA,CALF,CAHF,EAUE;AACA;AACD,WAjBD,CAmBA;;;AACAF,UAAAA,GAAG,GACDR,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,EAAgBc,GAAhB,CAAoBP,MAApB,GAA6BV,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,EAAgBe,KAAhB,CAAsBR,MAAnD,GAA4D,CAA5D,IACAV,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBe,GAAjB,CAAqBP,MAArB,GAA8BV,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBgB,KAAjB,CAAuBR,MAArD,GAA8D,CAD9D,GAEI,CAFJ,GAGI,CAJN;AAMA,gBAAMQ,KAAK,GAAGC,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBpB,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,EAAgBc,GAAlC,CAAd;AACA,gBAAMA,GAAG,GAAGE,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBpB,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBgB,KAAnC,CAAZ;AACAG,UAAAA,SAAS,CAACH,KAAD,EAAQ,CAACV,GAAT,CAAT;AACAa,UAAAA,SAAS,CAACJ,GAAD,EAAMT,GAAN,CAAT;AAEAF,UAAAA,eAAe,GAAG;AAChBM,YAAAA,IAAI,EAAEJ,GAAG,GAAG,CAAN,GAAUhB,KAAK,CAAC8B,cAAhB,GAAiC9B,KAAK,CAAC+B,gBAD7B;AAEhBL,YAAAA,KAFgB;AAGhBD,YAAAA,GAAG,EAAEE,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBpB,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,EAAgBc,GAAlC;AAHW,WAAlB;AAKAV,UAAAA,eAAe,GAAG;AAChBK,YAAAA,IAAI,EAAEJ,GAAG,GAAG,CAAN,GAAUhB,KAAK,CAAC8B,cAAhB,GAAiC9B,KAAK,CAAC+B,gBAD7B;AAEhBL,YAAAA,KAAK,EAAEC,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBpB,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBgB,KAAnC,CAFS;AAGhBD,YAAAA;AAHgB,WAAlB;AAKAZ,UAAAA,IAAI,GAAG;AACLO,YAAAA,IAAI,EAAEJ,GAAG,GAAG,CAAN,GAAUhB,KAAK,CAACgC,UAAhB,GAA6BhC,KAAK,CAACiC,YADpC;AAELP,YAAAA,KAAK,EAAEC,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBpB,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,EAAgBc,GAAlC,CAFF;AAGLA,YAAAA,GAAG,EAAEE,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBpB,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBgB,KAAnC;AAHA,WAAP;AAKAd,UAAAA,KAAK,GAAG;AACNQ,YAAAA,IAAI,EAAEJ,GAAG,GAAG,CAAN,GAAUhB,KAAK,CAACkC,MAAhB,GAAyBlC,KAAK,CAACmC,QAD/B;AAENT,YAAAA,KAAK,EAAEC,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBd,eAAe,CAACY,KAAlC,CAFD;AAGND,YAAAA,GAAG,EAAEE,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBb,eAAe,CAACU,GAAlC;AAHC,WAAR;AAMAjB,UAAAA,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,EAAgBc,GAAhB,GAAsBE,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBd,eAAe,CAACY,KAAlC,CAAtB;AACAlB,UAAAA,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBgB,KAAjB,GAAyBC,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBb,eAAe,CAACU,GAAlC,CAAzB;AAEAR,UAAAA,UAAU,GAAG,EAAb,CAvDA,CAyDA;;AACA,cAAIT,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,EAAgBc,GAAhB,CAAoBP,MAApB,GAA6BV,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,EAAgBe,KAAhB,CAAsBR,MAAvD,EAA+D;AAC7DD,YAAAA,UAAU,GAAGvB,IAAI,CAACuB,UAAD,EAAa,CAC5B,CAAC,OAAD,EAAUT,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,CAAV,EAA2BF,OAA3B,CAD4B,EAE5B,CAAC,MAAD,EAASD,MAAM,CAACG,IAAD,CAAN,CAAa,CAAb,CAAT,EAA0BF,OAA1B,CAF4B,CAAb,CAAjB;AAID,WA/DD,CAiEA;;;AACAQ,UAAAA,UAAU,GAAGvB,IAAI,CAACuB,UAAD,EAAa,CAC5B,CAAC,OAAD,EAAUL,KAAV,EAAiBH,OAAjB,CAD4B,EAE5B,CAAC,OAAD,EAAUK,eAAV,EAA2BL,OAA3B,CAF4B,EAG5B,CAAC,MAAD,EAASK,eAAT,EAA0BL,OAA1B,CAH4B,EAI5B,CAAC,OAAD,EAAUI,IAAV,EAAgBJ,OAAhB,CAJ4B,CAAb,CAAjB,CAlEA,CAyEA;;AACAP,UAAAA,MAAM,CACJO,OAAO,CAAC2B,MAAR,CAAeC,UAAf,CAA0BC,UAA1B,CAAqCC,IADjC,EAEJ,uCAFI,CAAN,CA1EA,CA+EA;;AACAtB,UAAAA,UAAU,GAAGvB,IAAI,CACfuB,UADe,EAEfpB,UAAU,CACRY,OAAO,CAAC2B,MAAR,CAAeC,UAAf,CAA0BC,UAA1B,CAAqCC,IAD7B,EAER/B,MAAM,CAACgC,KAAP,CAAa7B,IAAI,GAAG,CAApB,EAAuBD,KAAvB,CAFQ,EAGRD,OAHQ,CAFK,CAAjB,CAhFA,CAyFA;;AACAQ,UAAAA,UAAU,GAAGvB,IAAI,CAACuB,UAAD,EAAa,CAC5B,CAAC,MAAD,EAASJ,IAAT,EAAeJ,OAAf,CAD4B,EAE5B,CAAC,OAAD,EAAUM,eAAV,EAA2BN,OAA3B,CAF4B,EAG5B,CAAC,MAAD,EAASM,eAAT,EAA0BN,OAA1B,CAH4B,EAI5B,CAAC,MAAD,EAASG,KAAT,EAAgBH,OAAhB,CAJ4B,CAAb,CAAjB,CA1FA,CAiGA;;AACA,cAAID,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBe,GAAjB,CAAqBP,MAArB,GAA8BV,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBgB,KAAjB,CAAuBR,MAAzD,EAAiE;AAC/DA,YAAAA,MAAM,GAAG,CAAT;AACAD,YAAAA,UAAU,GAAGvB,IAAI,CAACuB,UAAD,EAAa,CAC5B,CAAC,OAAD,EAAUT,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,CAAV,EAA4BD,OAA5B,CAD4B,EAE5B,CAAC,MAAD,EAASD,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,CAAT,EAA2BD,OAA3B,CAF4B,CAAb,CAAjB;AAID,WAND,MAMO;AACLS,YAAAA,MAAM,GAAG,CAAT;AACD;;AAEDvB,UAAAA,MAAM,CAACa,MAAD,EAASG,IAAI,GAAG,CAAhB,EAAmBD,KAAK,GAAGC,IAAR,GAAe,CAAlC,EAAqCM,UAArC,CAAN;AAEAP,UAAAA,KAAK,GAAGC,IAAI,GAAGM,UAAU,CAACE,MAAlB,GAA2BD,MAA3B,GAAoC,CAA5C;AACA;AACD;AACF;AACF;AACF,GA7J2C,CA+J5C;;;AACAR,EAAAA,KAAK,GAAG,CAAC,CAAT;;AAEA,SAAO,EAAEA,KAAF,GAAUF,MAAM,CAACW,MAAxB,EAAgC;AAC9B,QAAIX,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBU,IAAjB,KAA0B,mBAA9B,EAAmD;AACjDZ,MAAAA,MAAM,CAACE,KAAD,CAAN,CAAc,CAAd,EAAiBU,IAAjB,GAAwB,MAAxB;AACD;AACF;;AAED,SAAOZ,MAAP;AACD;AAED;AACA;AACA;AACA;;;AACA,SAASF,iBAAT,CAA2BmC,OAA3B,EAAoCxC,EAApC,EAAwC;AACtC,QAAMyC,gBAAgB,GAAG,KAAKN,MAAL,CAAYC,UAAZ,CAAuBK,gBAAvB,CAAwCH,IAAjE;AACA,QAAMI,QAAQ,GAAG,KAAKA,QAAtB;AACA,QAAMC,MAAM,GAAGhD,iBAAiB,CAAC+C,QAAD,CAAhC;AAEA;;AACA,MAAIE,MAAJ;AAEA,SAAOnB,KAAP;AAEA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACE,WAASA,KAAT,CAAeoB,IAAf,EAAqB;AACnB5C,IAAAA,MAAM,CACJ4C,IAAI,KAAKhD,KAAK,CAACiD,QAAf,IAA2BD,IAAI,KAAKhD,KAAK,CAACkD,UADtC,EAEJ,iCAFI,CAAN;AAIAH,IAAAA,MAAM,GAAGC,IAAT;AACAL,IAAAA,OAAO,CAACQ,KAAR,CAAc,mBAAd;AACA,WAAOC,MAAM,CAACJ,IAAD,CAAb;AACD;AAED;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACE,WAASI,MAAT,CAAgBJ,IAAhB,EAAsB;AACpB,QAAIA,IAAI,KAAKD,MAAb,EAAqB;AACnBJ,MAAAA,OAAO,CAACU,OAAR,CAAgBL,IAAhB;AACA,aAAOI,MAAP;AACD;;AAED,UAAME,KAAK,GAAGX,OAAO,CAACY,IAAR,CAAa,mBAAb,CAAd,CANoB,CAQpB;;AACA,UAAMC,KAAK,GAAG1D,iBAAiB,CAACkD,IAAD,CAA/B,CAToB,CAWpB;;AACA5C,IAAAA,MAAM,CAACwC,gBAAD,EAAmB,6CAAnB,CAAN;AAEA,UAAM/B,IAAI,GACR,CAAC2C,KAAD,IACCA,KAAK,KAAKvD,SAAS,CAACwD,yBAApB,IAAiDX,MADlD,IAEAF,gBAAgB,CAACc,QAAjB,CAA0BV,IAA1B,CAHF;AAIA,UAAMW,KAAK,GACT,CAACb,MAAD,IACCA,MAAM,KAAK7C,SAAS,CAACwD,yBAArB,IAAkDD,KADnD,IAEAZ,gBAAgB,CAACc,QAAjB,CAA0Bb,QAA1B,CAHF;AAKAS,IAAAA,KAAK,CAAC9B,KAAN,GAAcoC,OAAO,CACnBb,MAAM,KAAK/C,KAAK,CAACiD,QAAjB,GAA4BpC,IAA5B,GAAmCA,IAAI,KAAKiC,MAAM,IAAI,CAACa,KAAhB,CADpB,CAArB;AAGAL,IAAAA,KAAK,CAAC/B,MAAN,GAAeqC,OAAO,CACpBb,MAAM,KAAK/C,KAAK,CAACiD,QAAjB,GAA4BU,KAA5B,GAAoCA,KAAK,KAAKH,KAAK,IAAI,CAAC3C,IAAf,CADrB,CAAtB;AAGA,WAAOV,EAAE,CAAC6C,IAAD,CAAT;AACD;AACF;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASjB,SAAT,CAAmB8B,KAAnB,EAA0BzC,MAA1B,EAAkC;AAChCyC,EAAAA,KAAK,CAACC,MAAN,IAAgB1C,MAAhB;AACAyC,EAAAA,KAAK,CAACzC,MAAN,IAAgBA,MAAhB;AACAyC,EAAAA,KAAK,CAACE,YAAN,IAAsB3C,MAAtB;AACD","sourcesContent":["/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {push, splice} from 'micromark-util-chunked'\nimport {classifyCharacter} from 'micromark-util-classify-character'\nimport {resolveAll} from 'micromark-util-resolve-all'\nimport {codes} from 'micromark-util-symbol/codes.js'\nimport {constants} from 'micromark-util-symbol/constants.js'\nimport {types} from 'micromark-util-symbol/types.js'\nimport {ok as assert} from 'uvu/assert'\n\n/** @type {Construct} */\nexport const attention = {\n  name: 'attention',\n  tokenize: tokenizeAttention,\n  resolveAll: resolveAllAttention\n}\n\n/**\n * Take all events and resolve attention to emphasis or strong.\n *\n * @type {Resolver}\n */\nfunction resolveAllAttention(events, context) {\n  let index = -1\n  /** @type {number} */\n  let open\n  /** @type {Token} */\n  let group\n  /** @type {Token} */\n  let text\n  /** @type {Token} */\n  let openingSequence\n  /** @type {Token} */\n  let closingSequence\n  /** @type {number} */\n  let use\n  /** @type {Array<Event>} */\n  let nextEvents\n  /** @type {number} */\n  let offset\n\n  // Walk through all events.\n  //\n  // Note: performance of this is fine on an mb of normal markdown, but it’s\n  // a bottleneck for malicious stuff.\n  while (++index < events.length) {\n    // Find a token that can close.\n    if (\n      events[index][0] === 'enter' &&\n      events[index][1].type === 'attentionSequence' &&\n      events[index][1]._close\n    ) {\n      open = index\n\n      // Now walk back to find an opener.\n      while (open--) {\n        // Find a token that can open the closer.\n        if (\n          events[open][0] === 'exit' &&\n          events[open][1].type === 'attentionSequence' &&\n          events[open][1]._open &&\n          // If the markers are the same:\n          context.sliceSerialize(events[open][1]).charCodeAt(0) ===\n            context.sliceSerialize(events[index][1]).charCodeAt(0)\n        ) {\n          // If the opening can close or the closing can open,\n          // and the close size *is not* a multiple of three,\n          // but the sum of the opening and closing size *is* multiple of three,\n          // then don’t match.\n          if (\n            (events[open][1]._close || events[index][1]._open) &&\n            (events[index][1].end.offset - events[index][1].start.offset) % 3 &&\n            !(\n              (events[open][1].end.offset -\n                events[open][1].start.offset +\n                events[index][1].end.offset -\n                events[index][1].start.offset) %\n              3\n            )\n          ) {\n            continue\n          }\n\n          // Number of markers to use from the sequence.\n          use =\n            events[open][1].end.offset - events[open][1].start.offset > 1 &&\n            events[index][1].end.offset - events[index][1].start.offset > 1\n              ? 2\n              : 1\n\n          const start = Object.assign({}, events[open][1].end)\n          const end = Object.assign({}, events[index][1].start)\n          movePoint(start, -use)\n          movePoint(end, use)\n\n          openingSequence = {\n            type: use > 1 ? types.strongSequence : types.emphasisSequence,\n            start,\n            end: Object.assign({}, events[open][1].end)\n          }\n          closingSequence = {\n            type: use > 1 ? types.strongSequence : types.emphasisSequence,\n            start: Object.assign({}, events[index][1].start),\n            end\n          }\n          text = {\n            type: use > 1 ? types.strongText : types.emphasisText,\n            start: Object.assign({}, events[open][1].end),\n            end: Object.assign({}, events[index][1].start)\n          }\n          group = {\n            type: use > 1 ? types.strong : types.emphasis,\n            start: Object.assign({}, openingSequence.start),\n            end: Object.assign({}, closingSequence.end)\n          }\n\n          events[open][1].end = Object.assign({}, openingSequence.start)\n          events[index][1].start = Object.assign({}, closingSequence.end)\n\n          nextEvents = []\n\n          // If there are more markers in the opening, add them before.\n          if (events[open][1].end.offset - events[open][1].start.offset) {\n            nextEvents = push(nextEvents, [\n              ['enter', events[open][1], context],\n              ['exit', events[open][1], context]\n            ])\n          }\n\n          // Opening.\n          nextEvents = push(nextEvents, [\n            ['enter', group, context],\n            ['enter', openingSequence, context],\n            ['exit', openingSequence, context],\n            ['enter', text, context]\n          ])\n\n          // Always populated by defaults.\n          assert(\n            context.parser.constructs.insideSpan.null,\n            'expected `insideSpan` to be populated'\n          )\n\n          // Between.\n          nextEvents = push(\n            nextEvents,\n            resolveAll(\n              context.parser.constructs.insideSpan.null,\n              events.slice(open + 1, index),\n              context\n            )\n          )\n\n          // Closing.\n          nextEvents = push(nextEvents, [\n            ['exit', text, context],\n            ['enter', closingSequence, context],\n            ['exit', closingSequence, context],\n            ['exit', group, context]\n          ])\n\n          // If there are more markers in the closing, add them after.\n          if (events[index][1].end.offset - events[index][1].start.offset) {\n            offset = 2\n            nextEvents = push(nextEvents, [\n              ['enter', events[index][1], context],\n              ['exit', events[index][1], context]\n            ])\n          } else {\n            offset = 0\n          }\n\n          splice(events, open - 1, index - open + 3, nextEvents)\n\n          index = open + nextEvents.length - offset - 2\n          break\n        }\n      }\n    }\n  }\n\n  // Remove remaining sequences.\n  index = -1\n\n  while (++index < events.length) {\n    if (events[index][1].type === 'attentionSequence') {\n      events[index][1].type = 'data'\n    }\n  }\n\n  return events\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeAttention(effects, ok) {\n  const attentionMarkers = this.parser.constructs.attentionMarkers.null\n  const previous = this.previous\n  const before = classifyCharacter(previous)\n\n  /** @type {NonNullable<Code>} */\n  let marker\n\n  return start\n\n  /**\n   * Before a sequence.\n   *\n   * ```markdown\n   * > | **\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    assert(\n      code === codes.asterisk || code === codes.underscore,\n      'expected asterisk or underscore'\n    )\n    marker = code\n    effects.enter('attentionSequence')\n    return inside(code)\n  }\n\n  /**\n   * In a sequence.\n   *\n   * ```markdown\n   * > | **\n   *     ^^\n   * ```\n   *\n   * @type {State}\n   */\n  function inside(code) {\n    if (code === marker) {\n      effects.consume(code)\n      return inside\n    }\n\n    const token = effects.exit('attentionSequence')\n\n    // To do: next major: move this to resolver, just like `markdown-rs`.\n    const after = classifyCharacter(code)\n\n    // Always populated by defaults.\n    assert(attentionMarkers, 'expected `attentionMarkers` to be populated')\n\n    const open =\n      !after ||\n      (after === constants.characterGroupPunctuation && before) ||\n      attentionMarkers.includes(code)\n    const close =\n      !before ||\n      (before === constants.characterGroupPunctuation && after) ||\n      attentionMarkers.includes(previous)\n\n    token._open = Boolean(\n      marker === codes.asterisk ? open : open && (before || !close)\n    )\n    token._close = Boolean(\n      marker === codes.asterisk ? close : close && (after || !open)\n    )\n    return ok(code)\n  }\n}\n\n/**\n * Move a point a bit.\n *\n * Note: `move` only works inside lines! It’s not possible to move past other\n * chunks (replacement characters, tabs, or line endings).\n *\n * @param {Point} point\n * @param {number} offset\n * @returns {void}\n */\nfunction movePoint(point, offset) {\n  point.column += offset\n  point.offset += offset\n  point._bufferIndex += offset\n}\n"]},"metadata":{},"sourceType":"module"}