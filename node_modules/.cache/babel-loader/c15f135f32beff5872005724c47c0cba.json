{"ast":null,"code":"/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { subtokenize } from 'micromark-util-subtokenize';\nimport { codes } from 'micromark-util-symbol/codes.js';\nimport { constants } from 'micromark-util-symbol/constants.js';\nimport { types } from 'micromark-util-symbol/types.js';\nimport { ok as assert } from 'uvu/assert';\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\n\nexport const content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent\n};\n/** @type {Construct} */\n\nconst continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n};\n/**\n * Content is transparent: it’s parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\n\nfunction resolveContent(events) {\n  subtokenize(events);\n  return events;\n}\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\n\n\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token | undefined} */\n  let previous;\n  return chunkStart;\n  /**\n   * Before a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n\n  function chunkStart(code) {\n    assert(code !== codes.eof && !markdownLineEnding(code), 'expected no eof or eol');\n    effects.enter(types.content);\n    previous = effects.enter(types.chunkContent, {\n      contentType: constants.contentTypeContent\n    });\n    return chunkInside(code);\n  }\n  /**\n   * In a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^^^\n   * ```\n   *\n   * @type {State}\n   */\n\n\n  function chunkInside(code) {\n    if (code === codes.eof) {\n      return contentEnd(code);\n    } // To do: in `markdown-rs`, each line is parsed on its own, and everything\n    // is stitched together resolving.\n\n\n    if (markdownLineEnding(code)) {\n      return effects.check(continuationConstruct, contentContinue, contentEnd)(code);\n    } // Data.\n\n\n    effects.consume(code);\n    return chunkInside;\n  }\n  /**\n   *\n   *\n   * @type {State}\n   */\n\n\n  function contentEnd(code) {\n    effects.exit(types.chunkContent);\n    effects.exit(types.content);\n    return ok(code);\n  }\n  /**\n   *\n   *\n   * @type {State}\n   */\n\n\n  function contentContinue(code) {\n    assert(markdownLineEnding(code), 'expected eol');\n    effects.consume(code);\n    effects.exit(types.chunkContent);\n    assert(previous, 'expected previous token');\n    previous.next = effects.enter(types.chunkContent, {\n      contentType: constants.contentTypeContent,\n      previous\n    });\n    previous = previous.next;\n    return chunkInside;\n  }\n}\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\n\n\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this;\n  return startLookahead;\n  /**\n   *\n   *\n   * @type {State}\n   */\n\n  function startLookahead(code) {\n    assert(markdownLineEnding(code), 'expected a line ending');\n    effects.exit(types.chunkContent);\n    effects.enter(types.lineEnding);\n    effects.consume(code);\n    effects.exit(types.lineEnding);\n    return factorySpace(effects, prefixed, types.linePrefix);\n  }\n  /**\n   *\n   *\n   * @type {State}\n   */\n\n\n  function prefixed(code) {\n    if (code === codes.eof || markdownLineEnding(code)) {\n      return nok(code);\n    } // Always populated by defaults.\n\n\n    assert(self.parser.constructs.disable.null, 'expected `disable.null` to be populated');\n    const tail = self.events[self.events.length - 1];\n\n    if (!self.parser.constructs.disable.null.includes('codeIndented') && tail && tail[1].type === types.linePrefix && tail[2].sliceSerialize(tail[1], true).length >= constants.tabSize) {\n      return ok(code);\n    }\n\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code);\n  }\n}","map":{"version":3,"sources":["D:/com lab/react/keerthana/auth2/AuthInMern/client/node_modules/micromark-core-commonmark/dev/lib/content.js"],"names":["factorySpace","markdownLineEnding","subtokenize","codes","constants","types","ok","assert","content","tokenize","tokenizeContent","resolve","resolveContent","continuationConstruct","tokenizeContinuation","partial","events","effects","previous","chunkStart","code","eof","enter","chunkContent","contentType","contentTypeContent","chunkInside","contentEnd","check","contentContinue","consume","exit","next","nok","self","startLookahead","lineEnding","prefixed","linePrefix","parser","constructs","disable","null","tail","length","includes","type","sliceSerialize","tabSize","interrupt","flow"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAAQA,YAAR,QAA2B,yBAA3B;AACA,SAAQC,kBAAR,QAAiC,0BAAjC;AACA,SAAQC,WAAR,QAA0B,4BAA1B;AACA,SAAQC,KAAR,QAAoB,gCAApB;AACA,SAAQC,SAAR,QAAwB,oCAAxB;AACA,SAAQC,KAAR,QAAoB,gCAApB;AACA,SAAQC,EAAE,IAAIC,MAAd,QAA2B,YAA3B;AAEA;AACA;AACA;AACA;;AACA,OAAO,MAAMC,OAAO,GAAG;AAACC,EAAAA,QAAQ,EAAEC,eAAX;AAA4BC,EAAAA,OAAO,EAAEC;AAArC,CAAhB;AAEP;;AACA,MAAMC,qBAAqB,GAAG;AAACJ,EAAAA,QAAQ,EAAEK,oBAAX;AAAiCC,EAAAA,OAAO,EAAE;AAA1C,CAA9B;AAEA;AACA;AACA;AACA;AACA;AACA;;AACA,SAASH,cAAT,CAAwBI,MAAxB,EAAgC;AAC9Bd,EAAAA,WAAW,CAACc,MAAD,CAAX;AACA,SAAOA,MAAP;AACD;AAED;AACA;AACA;AACA;;;AACA,SAASN,eAAT,CAAyBO,OAAzB,EAAkCX,EAAlC,EAAsC;AACpC;AACA,MAAIY,QAAJ;AAEA,SAAOC,UAAP;AAEA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACE,WAASA,UAAT,CAAoBC,IAApB,EAA0B;AACxBb,IAAAA,MAAM,CACJa,IAAI,KAAKjB,KAAK,CAACkB,GAAf,IAAsB,CAACpB,kBAAkB,CAACmB,IAAD,CADrC,EAEJ,wBAFI,CAAN;AAKAH,IAAAA,OAAO,CAACK,KAAR,CAAcjB,KAAK,CAACG,OAApB;AACAU,IAAAA,QAAQ,GAAGD,OAAO,CAACK,KAAR,CAAcjB,KAAK,CAACkB,YAApB,EAAkC;AAC3CC,MAAAA,WAAW,EAAEpB,SAAS,CAACqB;AADoB,KAAlC,CAAX;AAGA,WAAOC,WAAW,CAACN,IAAD,CAAlB;AACD;AAED;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACE,WAASM,WAAT,CAAqBN,IAArB,EAA2B;AACzB,QAAIA,IAAI,KAAKjB,KAAK,CAACkB,GAAnB,EAAwB;AACtB,aAAOM,UAAU,CAACP,IAAD,CAAjB;AACD,KAHwB,CAKzB;AACA;;;AACA,QAAInB,kBAAkB,CAACmB,IAAD,CAAtB,EAA8B;AAC5B,aAAOH,OAAO,CAACW,KAAR,CACLf,qBADK,EAELgB,eAFK,EAGLF,UAHK,EAILP,IAJK,CAAP;AAKD,KAbwB,CAezB;;;AACAH,IAAAA,OAAO,CAACa,OAAR,CAAgBV,IAAhB;AACA,WAAOM,WAAP;AACD;AAED;AACF;AACA;AACA;AACA;;;AACE,WAASC,UAAT,CAAoBP,IAApB,EAA0B;AACxBH,IAAAA,OAAO,CAACc,IAAR,CAAa1B,KAAK,CAACkB,YAAnB;AACAN,IAAAA,OAAO,CAACc,IAAR,CAAa1B,KAAK,CAACG,OAAnB;AACA,WAAOF,EAAE,CAACc,IAAD,CAAT;AACD;AAED;AACF;AACA;AACA;AACA;;;AACE,WAASS,eAAT,CAAyBT,IAAzB,EAA+B;AAC7Bb,IAAAA,MAAM,CAACN,kBAAkB,CAACmB,IAAD,CAAnB,EAA2B,cAA3B,CAAN;AACAH,IAAAA,OAAO,CAACa,OAAR,CAAgBV,IAAhB;AACAH,IAAAA,OAAO,CAACc,IAAR,CAAa1B,KAAK,CAACkB,YAAnB;AACAhB,IAAAA,MAAM,CAACW,QAAD,EAAW,yBAAX,CAAN;AACAA,IAAAA,QAAQ,CAACc,IAAT,GAAgBf,OAAO,CAACK,KAAR,CAAcjB,KAAK,CAACkB,YAApB,EAAkC;AAChDC,MAAAA,WAAW,EAAEpB,SAAS,CAACqB,kBADyB;AAEhDP,MAAAA;AAFgD,KAAlC,CAAhB;AAIAA,IAAAA,QAAQ,GAAGA,QAAQ,CAACc,IAApB;AACA,WAAON,WAAP;AACD;AACF;AAED;AACA;AACA;AACA;;;AACA,SAASZ,oBAAT,CAA8BG,OAA9B,EAAuCX,EAAvC,EAA2C2B,GAA3C,EAAgD;AAC9C,QAAMC,IAAI,GAAG,IAAb;AAEA,SAAOC,cAAP;AAEA;AACF;AACA;AACA;AACA;;AACE,WAASA,cAAT,CAAwBf,IAAxB,EAA8B;AAC5Bb,IAAAA,MAAM,CAACN,kBAAkB,CAACmB,IAAD,CAAnB,EAA2B,wBAA3B,CAAN;AACAH,IAAAA,OAAO,CAACc,IAAR,CAAa1B,KAAK,CAACkB,YAAnB;AACAN,IAAAA,OAAO,CAACK,KAAR,CAAcjB,KAAK,CAAC+B,UAApB;AACAnB,IAAAA,OAAO,CAACa,OAAR,CAAgBV,IAAhB;AACAH,IAAAA,OAAO,CAACc,IAAR,CAAa1B,KAAK,CAAC+B,UAAnB;AACA,WAAOpC,YAAY,CAACiB,OAAD,EAAUoB,QAAV,EAAoBhC,KAAK,CAACiC,UAA1B,CAAnB;AACD;AAED;AACF;AACA;AACA;AACA;;;AACE,WAASD,QAAT,CAAkBjB,IAAlB,EAAwB;AACtB,QAAIA,IAAI,KAAKjB,KAAK,CAACkB,GAAf,IAAsBpB,kBAAkB,CAACmB,IAAD,CAA5C,EAAoD;AAClD,aAAOa,GAAG,CAACb,IAAD,CAAV;AACD,KAHqB,CAKtB;;;AACAb,IAAAA,MAAM,CACJ2B,IAAI,CAACK,MAAL,CAAYC,UAAZ,CAAuBC,OAAvB,CAA+BC,IAD3B,EAEJ,yCAFI,CAAN;AAKA,UAAMC,IAAI,GAAGT,IAAI,CAAClB,MAAL,CAAYkB,IAAI,CAAClB,MAAL,CAAY4B,MAAZ,GAAqB,CAAjC,CAAb;;AAEA,QACE,CAACV,IAAI,CAACK,MAAL,CAAYC,UAAZ,CAAuBC,OAAvB,CAA+BC,IAA/B,CAAoCG,QAApC,CAA6C,cAA7C,CAAD,IACAF,IADA,IAEAA,IAAI,CAAC,CAAD,CAAJ,CAAQG,IAAR,KAAiBzC,KAAK,CAACiC,UAFvB,IAGAK,IAAI,CAAC,CAAD,CAAJ,CAAQI,cAAR,CAAuBJ,IAAI,CAAC,CAAD,CAA3B,EAAgC,IAAhC,EAAsCC,MAAtC,IAAgDxC,SAAS,CAAC4C,OAJ5D,EAKE;AACA,aAAO1C,EAAE,CAACc,IAAD,CAAT;AACD;;AAED,WAAOH,OAAO,CAACgC,SAAR,CAAkBf,IAAI,CAACK,MAAL,CAAYC,UAAZ,CAAuBU,IAAzC,EAA+CjB,GAA/C,EAAoD3B,EAApD,EAAwDc,IAAxD,CAAP;AACD;AACF","sourcesContent":["/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {subtokenize} from 'micromark-util-subtokenize'\nimport {codes} from 'micromark-util-symbol/codes.js'\nimport {constants} from 'micromark-util-symbol/constants.js'\nimport {types} from 'micromark-util-symbol/types.js'\nimport {ok as assert} from 'uvu/assert'\n\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\nexport const content = {tokenize: tokenizeContent, resolve: resolveContent}\n\n/** @type {Construct} */\nconst continuationConstruct = {tokenize: tokenizeContinuation, partial: true}\n\n/**\n * Content is transparent: it’s parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\nfunction resolveContent(events) {\n  subtokenize(events)\n  return events\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token | undefined} */\n  let previous\n\n  return chunkStart\n\n  /**\n   * Before a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function chunkStart(code) {\n    assert(\n      code !== codes.eof && !markdownLineEnding(code),\n      'expected no eof or eol'\n    )\n\n    effects.enter(types.content)\n    previous = effects.enter(types.chunkContent, {\n      contentType: constants.contentTypeContent\n    })\n    return chunkInside(code)\n  }\n\n  /**\n   * In a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function chunkInside(code) {\n    if (code === codes.eof) {\n      return contentEnd(code)\n    }\n\n    // To do: in `markdown-rs`, each line is parsed on its own, and everything\n    // is stitched together resolving.\n    if (markdownLineEnding(code)) {\n      return effects.check(\n        continuationConstruct,\n        contentContinue,\n        contentEnd\n      )(code)\n    }\n\n    // Data.\n    effects.consume(code)\n    return chunkInside\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function contentEnd(code) {\n    effects.exit(types.chunkContent)\n    effects.exit(types.content)\n    return ok(code)\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function contentContinue(code) {\n    assert(markdownLineEnding(code), 'expected eol')\n    effects.consume(code)\n    effects.exit(types.chunkContent)\n    assert(previous, 'expected previous token')\n    previous.next = effects.enter(types.chunkContent, {\n      contentType: constants.contentTypeContent,\n      previous\n    })\n    previous = previous.next\n    return chunkInside\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this\n\n  return startLookahead\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function startLookahead(code) {\n    assert(markdownLineEnding(code), 'expected a line ending')\n    effects.exit(types.chunkContent)\n    effects.enter(types.lineEnding)\n    effects.consume(code)\n    effects.exit(types.lineEnding)\n    return factorySpace(effects, prefixed, types.linePrefix)\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function prefixed(code) {\n    if (code === codes.eof || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    // Always populated by defaults.\n    assert(\n      self.parser.constructs.disable.null,\n      'expected `disable.null` to be populated'\n    )\n\n    const tail = self.events[self.events.length - 1]\n\n    if (\n      !self.parser.constructs.disable.null.includes('codeIndented') &&\n      tail &&\n      tail[1].type === types.linePrefix &&\n      tail[2].sliceSerialize(tail[1], true).length >= constants.tabSize\n    ) {\n      return ok(code)\n    }\n\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code)\n  }\n}\n"]},"metadata":{},"sourceType":"module"}